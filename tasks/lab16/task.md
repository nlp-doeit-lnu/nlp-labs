# Лабораторна робота №16

## Закони Ціпфа та Парето для слів у текстах

### Завдання

1. Згенерувати по одному тексту кожного з п'яти типів:

    - текст мавпи Міллера;

    - рандомізований текст;

    - текст Маркова;

    - текст Саймона;

    - текст Поля.

2. Дослідити виконання законів Ціпфа, Парето для отриманих текстів.

### Порядок виконання роботи 

1. Ознайомтеся з теорією опису основних рандомних моделей і рандомних текстів різних типів.

2. Згенеруйте тексти кожного з таких п’яти типів:

    - **Рандомізований текст** (це текст, який отримують перемішуванням лінгвістичних елементів вихідного природного тексту).  
    Ви можете використати одну з таких програм:
        
        - програма +shuffler(words only) --- вона перемішує текст лише на лінгвістичному рівневі слів.
        З бази текстів обираємо один текст і відкриваємо його за допомогою вкладки «Відкрити текст».
        Вкладка «Перемішувати», яка обирає, які саме елементи тексту (символи, слова чи речення) будуть переміщуватися, тут суто фор­мальна.
        У вкладці «Параметри» вказуємо кількість циклів перемішування та обираємо тип перемішування: «глобальний» або «локальний».
        У разі локального перемішування задаємо розмір N біжучого вікна, на якому відбувається перемішу­вання та номер лінгвістичного елемента, з якого починатиметься перемішу­вання елементів тексту.
        Генерований текст можна переглянути у вкладці «Вихідний текст» і зберегти, використавши вкладку «Зберегти текст»;

        - програма +shuffler_universal (скрипт `shuffler_universal` для `nlp-wine`) зі схожою до попередньої програми будовою, яка дає змоги перемішувати текст на будь-яких зі згаданих вище лінгвістичних рівнях;

        - програма +shuffler_fast&global, яка працює виключно в режимі глобального перемішування на всіх лінгвістичних рівнях.
        Проте програма не визначає кількості циклів рандомізації --- вона перемішує лінгвістичні елементи в тексті стільки разів, скільки цих елементів входять у текст (наприклад, якщо в тексті 1000 слів, то кількість перемішувань теж складає 1000).
        Це дає значний виграш у швидкодії.
        Програма додатково дає змогу перемішувати всі тексти в обраній папці;

        - програма +shuffler2023 (скрипт `shuffler2023` для `nlp-python`), яка відрізняється максимальною універсальністю та функціоналом, у т.ч. можливістю роботи з папками текстів.

    У цій роботі слід згенерувати текст, рандомізований на лексичному лінгвіс­тичному рівні. Кількість циклів рандомізації має бути не меншою за кількість слів у цьому тексті.

    - **Текст мавпи Міллера** (це текст, який отримуємо випадковим набором різних символів з алфавіту та пробілів).  
    Використати програму +monkey\_texts (скрипт `rt_monkey` для `nlp-wine`).
    У вкладці «Параметри» задаємо довжину тексту $L$ = 50000&ndash;500000, мову (українську або англійську), кількість букв (алфавіт) M, імовірність пробілу (можна задати окремо або разом з імовірностями букв), а також імовірність кожної букви (можна ввести з клавіатури або обрати випадковим чином – кнопка «Random»).
    Після вибору всіх параметрів генеруємо та зберігаємо текст.

    - **Текст Саймона** (слова для такого тексту обирають випадковим чином з одного або двох заданих словників).
    Для цього слугує програма +Simon_3in1 (скрипт `rt_simon` для `nlp-wine`).
    У вкладці «Генерація» обираємо одну з незалежних опцій генерації:
        
        - лінійна або нелінійна генерація;

        - генерація з одним або двома словниками.

    Разом одержуємо 3 типи генерації тексту з використанням двох словників. 
    Для обох словників є два поля з додатковими властивостями, які потрібно заповнити:

        - «p %»­--- це імовірність того, що наступне слово буде взято з даного словника;

        – «theta» – це коефіцієнт, який використовують у разі нелінійній генерації; він дорівнюватиме параметрові закону Гіпса.

        Поряд з цими полями також є два текстових поля, які показують користувачеві кіль­кість слів у завантаженому словнику та шлях до нього на диску.
        Деякі деталі процедури генерування текстів Саймона можна знайти в довідковому файлі Simon&memory_zvit.doc.

        Нарешті, програма +Simon_with memory (скрипт `rt_simon_with_memory`) дає змогу реалізувати ще одну додаткову опцію генерування текстів Саймона з пам’яттю.
        Тут на інтерфейсі слід виставити тип (фактично функцію загасання пам’яті з часом) і кількісні параметри цієї пам’яті.

    - **Текст Маркова** (такий текст можна будувати на лінгвістичних рівнях букв (символів) або слів --- див. матеріали [лабораторної роботи №18](../lab18/task.md)).
    Тут у програмі +Markov texts можна обрати тип ланки («букви», або «слова») і довжину ланцюжка N --- орієнтовно в діапазоні від 1 до 10.

    - **Текст Поля** (це текст, який генерують на основі однойменної статистичної моделі, суть якої пояснено в конспекті лекцій).
    Тут початкові розміри урни зі словами можна обрати в діапазоні від 10 000 до 100 000 слів, а цілочисельні параметри $\rho$ і $\nu$ можна обрати так: $\nu$ = 1&ndash;10, $\rho \less \nu$.

3. На додаток до пояснених вище параметрів, решту параметрів для кожного типу тексту можна обирати довільно в межах теоретично припустимих значень.
У звіті обов’язково вкажіть, з якими саме параметрами було згенеровано кожен текст.

4. Згідно з пунктом 2а, згенеруйте три тексти мавпи Міллера типу (b) і по одному рандомному тексту типів (а), (c)–(e).  
При цьому слід обрати два тексти мавпи Міллера з малими розмірами алфавіту і один текст з великим розміром алфавіту.
Наприклад, можна обрати розміри алфавіту M = 1, 5, 30 або M = 2, 3 і 25.

5. Вивчіть рангову залежність F(r), частотну залежність pmf(F), залежність кумулятивної ймовірності ccmf(F) і залежність розміру словника від розміру тексту V(L) для слів для кожного із генерованих текстів типів (b)–(e) так, як це робилося в лабораторних роботах [№2](../lab02/task.md) і [№3](../lab03/task.md).

    *Зауваження*: перевірка дотримання статистичних законів для рандомізованих текстів не потрібна, бо рандомізація не впливає на частоти символів або слів.
    Іншими словами, закони Ціпфа, Парето та Гіпса для рандомі­зованого тексту тотожні до тих же законів для початкового природного тексту, який рандомізували.

6. Перевірте, чи виконуються перший та другий закони Ціпфа, а також закони Парето і Гіпса на лінгвістичному рівневі слів для текстів Саймона, Маркова та Поля.

7. Порівняйте виконання статистичних законів Ціпфа, Парето і Гіпса для слів в альтер­нативних випадках текстів мавпи Міллера з великими і малими розмірами алфавіту М.
Як, на Вашу думку, можна пояснити «сходинки» на рангових залежностях $F(r)$ для текстів мавпи Міллера?
Чи виконується і з якою точністю виконується закон Гіпса для цих текстів, порівняно з природними текстами?

8. За допомогою програми ++repetition3.3jar (скрипт `repetition_parameter` для `nlp-java`) з [лабораторної роботи №23](../lab23/task.md) дослідіть залежність параметра повторюваності $v(t)$ для генерованих Вами рандомізованого тексту типу (а), природного тексту, який було піддано рандомізації, а також для трьох текстів мавпи Міллера типу (b).
    Користуючись цією програмою, найперше модифікуйте виконавчий файл Executable\_2023\_bigXXXGB.bat, де позначення «XXX» відповідає оптимальному обсягу оперативної пам’яті, яку Ви виділяєте на програму. Це дасть змогу оптимізувати роботу програми.
    В головному меню програми оберіть досліджуваний текстовий файл, в пункті меню «Analyze» оберіть режим роботи «A set of characters».
    Далі оберіть режим «plus 1 and first repetition», не прописуючи параметрів біжучого вікна справа, натисніть «Analyze» --- і одержите графік $v(t)$.

    Для докладнішого аналізу цих даних знову перейдіть до пунктів меню File -> Save result -> v(t) result.
    Верхня частина спливаючого меню визначає параметри збереження даних: тут поле «Save first \*n rows» визначає, скільки перших точок Ви збережете до файлу, а поле «save each \*m rows» --- через яку кількість точок Ви будете зберігати точки (наприклад, одну точку через 10 точок).
    Скажімо, якщо обрано n = 5, m = 20, то Ви збережете такі точки: 1, 2, 3, 4, 5, 25, 45, ... .

    Нижня частина спливаючого меню визначає особливості розрахунків середнього значення $v_0$ і с.к.в. $\Delta v$ параметра повторюваності, які набувають особливого значення у разі, якщо функція $v(t)$ прямує до визначеної величини зі зростанням позиції в тексті $t$.
    Величини $v(t)$ усереднюють, починаючи з деякого значення «Start from value t», а розрахунки йдуть із деяким кроком «Step between values t».
    Після введення цих величин і натискання кнопки «Calculate» одержуємо параметри «Average» $v_0$ і «Standard deviation» $\Delta v$.
    Параметри $v_0$ і $\Delta v$ підсумовують поведінку параметра повторюваності.

9. Визначте і випишіть параметри $v_0$ і $\Delta v$ для всіх текстів мавпи Міллера.
Порівняйте ці параметри для різних текстів та зробіть належні висновки.
Чому, на Вашу параметри $v_0$ для них різні?

10. Визначте і випишіть параметри $v_0$ і $\Delta v$ для природного тексту та відповідного рандомізованого тексту.
Порівняйте ці параметри між собою та зробіть належні висновки.
Чому, на Вашу параметри $v_0$ для них різні?

11. У висновках підсумуйте отримані Вами результати. Зокрема:

    - З’ясуйте, для яких типів текстів взаємні зв’язки між показниками різних статистичних законів $\alpha$, $\beta$, $k$ і $\theta$ збігаються з теоретично передбаченим, а для яких, можливо, ні?
    Чим, на Вашу думку, пояснюється останнє явище, якщо воно є?

    - Як пояснити відмінності в статистичних законах для текстів мавпи Міллера з малими та великими розмірами алфавіту?

    - Як пояснити закономірності поведінки параметра повторюваності рандомних текстів мавпи Міллера для великих і малих розмірів алфавіту?

    - Як пояснити відмінності параметрів повторюваності природних і рандомізо­ваних текстів?

    - Чи можна, на Вашу думку, використати закономірності для параметра повторю­ваності з метою розрізнен­ня природних і рандомних текстів?
