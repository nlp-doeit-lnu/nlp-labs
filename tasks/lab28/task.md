# Лабораторна робота №28

## Флуктуації та кореляції в текстах. Метод FA

### Завдання

використовуючи програми +FA010 і +FA&R\_all words(symbols)\_py, визначити параметри кореляцій для різних лінгвістичних елементів у природному та рандомному (рандо­мізо­ваному) текстах.

### Порядок виконання роботи

1. Попередня теоретична до роботи включає ознайомлення з відповідним розділом конспекту лекцій та прочитання доданих наукових статей про метод FA (Fluctuation Analysis).

2. Оберіть один природний і один рандомний текст (або рандомізований на рівні слів текст, побудований на основі Вашого природного тексту) із тих, які Ви досліджували в попередніх лабораторних роботах. 

3. Користуючись програмою +FA010, виконайте флуктуаційний аналіз для таких лінгвістичних елементів в обох досліджуваних текстах:
    a. для трьох букв, які мають такі властивості:
        – із високою (або навіть найвищою) абсолютною частотою $F$; 
        – середньою абсолютною частотою $F$; 
        – порівняно низькою абсолютною частотою $F$;
    b. для однієї буквеної n-грами (n = 2 або 3) з найвищою частотою $F$;

    c. для двох слів:
        – одного високочастотного функціонального слова (на зразок слів «the» або «on» в англійських текстах) із параметром кластеризації $R \approx 1$; 
        – одного змістового (або ключового) слова із високим показником кластеризації $R \gg 1$ (наприклад, R = 3, R = 6 тощо; такі слова можуть трапитися лише в природ­них текстах, а в рандомізованому тексті можете взяти слово, яке мало високу кластеризацію у вихідному природному тексті); таке слово повинно одно­часно мати порівняно високу частоту (скажімо, не меншу за F = 50&ndash;100), що забез­печує багату статистику. 
    
    Для визначення частот F слів у тексті і визначення параметрів R слів у тексті можете використати програму +NG.metrics\_R із [лабораторної роботи №26](../tasks/lab26).

4. Використовуючи програму +FA010 (скрипт `FA` для `nlp-wine`), слід спочатку обрати режим її роботи («слова» або «символи»).
Далі слід виставити максимальну ширину «End window size» wmax біжучого вікна, що приблизно дорівнює 5&ndash;10% від довжини тексту (тобто довжини часового ряду) $L = 10000$:
$$w_{max} = (0.05\div0.10)L.$$

Потім оберіть мінімальне вікно wmin, крок переміщення (H) і крок збільшення (K) вікна так, аби приблизно дотримувалися рівності
$$w_{min} = H = K,$$
і
$$w_{min} = w_{max}/N,$$
де $N = 100$.

5. Випишіть інформацію про назви текстів, обрані із них букви, n-граму та слова, їхні абсолютні частоти $F$, параметри кластеризації $R$, а також дані нелінійної апроксимації в програмі +FA010 для степеня кореляцій $\gamma$ і коефіцієнта якості апроксимації Goodness.

6. Далі слід «Зберегти в файл» таблиці з повними проміжними даними флуктуаційного аналізу в програмі +FA010, перенести їх у зовнішню програму аналізу графічних да­них (наприклад, у пакет Origin), побудувати графіки в подвійному логарифмічному масш­табі, провести лінійну апроксимацію і знайти відповідні показники степеня $\gamma$.
До­дати деталі апрокси­мації до кожного з графіків.

7. Порівняйте дані для $\gamma$, одержані безпосередньо в програмі +FA010 і в зовнішній про­грамі для побудови та аналізу графіків.
Зробіть висновок про наявність чи відсутність довгосяжних кореляцій для обраних Вами лінгвістичних елементів у природ­ному і рандомному текстах.
Нагадуємо, що $\gamma \approx 0.5$, якщо кореляції відсутні або короткосяжні, і $\gamma > 0.5$, якщо кореляції довгосяжні.

8. Користуючись програмою +text-into-bites+, здійсніть альтернативний спосіб приведення одного з Ваших текстів до числового ряду (див. файл README\_binary\_converter.txt), перетворивши текст на послідовність нулів і одиниць.
Збережіть цей файл і дослідіть його програмою +FA010, обравши режим роботи «символи» і Template = 1 (або 0).
Випишіть відповідні дані в звіт і зробіть висновок про наявність або відсутність довгосяжних кореляцій у тексті, виходячи з його внутрішньої структури.

*Зауваження*.
Зазначте, що програма +FA010 дає змогу вивчати кореляції бага­тьох (хоча й далеко не всіх можливих) лінгвістичних елементів.
Прикладами є символи, слова або n-грам на їхній основі.
Проте програму не можна безпосередньо засто­сувати до вивчення таких лінгвістичних елементів як, наприклад, слів на три літери; слів, що починаються з деякої літери; речень деякої довжини або речень, що містять деяке слово, букву або n-граму – і багато інших об’єктів.
Такі лінгвістичні об’єкти можна знайти за допомогою допоміжної програми +Xtractor-convertor-to-(0&1)series із [лабораторної роботи №25](../tasks/lab25.md).
Ця програма замінить шуканий у тексті лінгвістичний елемент (наприклад, речення на 3 слова або слово на 3 літери) на 1, а решта речень (або слів) – на 0.
Одержимо числовий ряд вигляду 01000101100... .
Кореляції в ньому надалі можна вивчати за допомогою програми +FA010.

9. Для зручності користування помістіть досліджувані Вами текстові файли в підпапку «Doc» папки з програмою +Xtractor-convertor-to-(0&1)series із [лабораторної роботи №25](../task/lab25.md).
Якщо назви Ваших текс­тів містять пробіли, то перейменуйте їх належно.
Це сто­сується й назв усіх підпапок аж до кореневої папки на диску, де записано програму та текстовий файл!

Отримайте позиції в одному із Ваших текстів деякого обраного Вами лінгвістичного елемента (до прикладу, слова, що починається з літери «n») за допомогою програми +Xtractor-convertor-to-(0&1)series.
Збережіть числовий ряд до файлу (див. закладку «10010...» внизу на інтерфейсі).
Пере­творіть цей файл на текстовий файл у форматі \*.txt із кодуванням UTF-8 і дослідіть його програмою +FA010.
Для цього можна використати або основний режим (опція «символи», Template = 1 або 0), або т. зв. «додатковий режим» роботи програми.

10. Засвойте роботу програми +FA&R\_all words(symbols)\_py.
Вона одночасно аналізує за методом FA всі символи, слова або їхні n-грами в тексті та видає усереднені по всіх таких лінгвістичних елементах дані для коефіцієнта кореляцій $\gamma$ і кластеризації $R$.

Програма має широкий функціонал: 

    – виводить у таблицю абсолютні частоти, ранги та параметри $R$ і $\gamma$ для всіх лінгвістичних елементів у тексті, а також коефіцієнт якості нелінійної апроксимації, за допомогою якої знаходять параметр $\gamma$; 

    – дає змогу спостерігати за тим, як будь-яке слово розподілено в тексті; 

    – ілюструє графік залежності флуктуацій від ширини вікна для будь-якого лінгвістичного елемента в звичайному та подвійному логарифмічному масштабах;

    – показує положення всіх лінгвістичних елементів на двовимірній «карті» з координатами $R$ і $\gamma$.

Зауважте, що на цій карті всі букви, слова та їхні n-грами, розміщені поблизу точки з координатами О(1; $\frac{1}{2}$) (тобто $R = 1$ і $\gamma = \frac{1}{2}$), не виявляють жодних кластеризації та довгосяжних кореляцій.
Водночас, лінгвістичні елементи, позиції яких на карті найпомітніше відхиляються від згаданої точки О, характеризуються і кластери­зацією, і довгосяжними кореляціями.
Типово це ключові слова тексту.
Відпо­відно, на карті, побудованій для рандомного (або рандомізованого) тексту, такі відда­лені точки мають бути відсутніми.
Винятками можуть бути лише лінгвістичні елемен­ти, частоти $F$ яких надто низькі, аби забезпечити надійну статистику та, відпо­відно, надійні дані $R$ і $\gamma$.

11. Тепер треба виконати флуктуаційний аналіз для обраних Вами текстів за допомогою програми +FA&R\_all words(symbols)\_py.
Помістіть обидва досліджувані Вами тексти в папку «corpus» програми.
Почергово опрацюйте кожен із цих текстів даною про­гра­мою.

Послідовність практичних дій така.
Запустіть програму.
У пункті меню «Choose file» оберіть текст, оберіть коректні довжину n-грами (n = 1, 2 або 3) і режим роботи програми («букви», «символи» або «слова»), далі оберіть опції «Boundary condition = periodic», «Filter = ...» у межах Filter = 10&ndash;20, залежно від розміру тексту (параметр Filter тим більший, що довший текст).
Решті параметрів залиште їхні дефолтні значення на інтерфейсі.
Далі натисніть «Analyze», дочекайтеся завершення робо­ти програми та натисніть «Save data».

Дані у формі таблиці Excel збережено в папці «saved\_data» програми (файл типу «title.txt condition=periodic,fmin=15,n=1,w=(31,31,31,638),definition=static»).
Це Ваші дані для обох текстів, які стосуються усіх букв у тексті, усіх буквених 2-грам або 3-грам у тексті та всіх слів у тексті.

12. Порівняйте величини параметрів $R$, $\gamma$ та інших параметрів кластеризації та кореляцій для букв, слів і буквених n-грам у природних і рандом­них (або рандомізованих) текстах і зробіть висновки.
Зокрема, чи помітні відмінності величин  і  для букв, слів і буквених n-грам у природних і рандомних текстах?
Чи можна використати ці відмінності для розрізнення цих альтернативних типів текстів?

13. Висновок повинен містити короткий опис виконаних Вами досліджень, аналіз і порівняння отриманих параметрів, а також висновки про наявність чи відсутність довгосяжних кореляцій і кластеризації в цих природному та рандомному текстах.


*Додаткове завдання*:

- за допомогою програми +FA010 дослідити кореляції елементів 0 або 1 у допоміжних рандомних текстах random text(0&1).txt у режимах «символи» та «слова».
